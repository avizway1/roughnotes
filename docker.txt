Lunch = application
lunch box = docker container

You can have your lunch box in classroom, mess, play ground, home.. 

evrything i.e; app: code, tools, settings, dependencies... : you can run it in your laptop, your friends laptop, cloud..

---



dnf install docker -y
systemctl start docker
systemctl enable docker
docker info

docker images				--> List the docker images we have in instance/laptop

docker run image-name/id	--> Runs the docker container, but in interactive way.

docker run -d image-name/id	--> Runs the docker container in detached mode.

docker ps					--> List the running containers

docker ps -a				--> List the running and stopped containers

docker rm container-id		--> This will remove the contianer

docker stop container-id	--> This comamnd will stop the container

docker start container-id	--> This comamnd will start the existing container

docker kill container-id	--> This comamnd will stop the container by sending kill signal.

docker run app-name		--> if image not available locally, it will pull the image from docker hub and runs the container. 

docker run -d -p <hostport>:<container-port> image-name:tag-name

docker run -d -p 8080:80 nginx:latest

docker exec -it container-id /bin/bash		--> You can use this command to connect to the container os.
docker exec -it container-id /bin/sh


docker run -d -p 80:80 nginx:latest
docker run -d -p 8080:80 nginx:latest

docker container prune		--> Remove all stopped cotnainers

docker run -dit -p 80:80 nginx:latest

docker run -dit -p 80:80 --name my-webserver nginx:latest		--> Container creates with custom defined name


docker inspect <container-id>


---

docker network ls					--> List the networks we have. 

NETWORK ID     NAME      DRIVER    SCOPE
f4442d918362   bridge    bridge    local
189c97d94a70   host      host      local
c1f2b41e3ed2   none      null      local

Bridge Mode : Docker defaultly creates an internal network. It will have its own IP address range. By performing the port mapping, you can deliver to outside world using instance IP Address. 

Host Mode : Container shared the host machine's network. 

None : Container without netwotk. 


---


docker network create mynetwork

docker run -dit --name web1 --network mynetwork alpine

docker run -dit --name web2 --network mynetwork alpine

docker exec -it web1 sh
ping web2


docker inspect 6e443f5c1b8e --> 172.18.0.3
docker inspect e73349d5bb87 --> 172.18.0.2

---

docker run -d --network host nginx		--> This creates a container with host network mode.

---

docker run -it --network none alpine /bin/sh	--> This creates a cotnainer and we connects to it, but no network. 


docker run -dit --network none --name test1 alpine

====================================================================================

Dockerfile Preparation:


FROM --> Define Base Image to use. 

FROM nginx:latest
FROM ubuntu:20.06

---

RUN --> Execute the commands in seperate layer on top of base Image. 

RUN dnf install telnet -y
RUN apt-get update && apt-get install -y nginx

---

WORKDIR --> Sets the default working directory

WORKDIR /app
WORKDIR /home/ec2-user/

---

COPY --> Copy the files/directories from the host to the image. 

COPY /home/ec2-user/myweb/* /app/
COPY . . 

---

ADD --> Similar to Copy command, but supports archieve extractions (.zip / .tar.gz)

ADD myzipfile.tar.gz /app/

---

CMD --> provides default arguments for the containers execution. This will be overridden, if we pass any arguments when running the container using "docker run".

CMD ["python", "app.py"]

--

ENTRYPOINT --> Defines a command that always runs, even if we pass any arguments when running the container using "docker run"

ENTRYPOINT ["python", "app.py"]

---

ENV --> Sets environment varibales

ENV APP_ENV=dev
ENV APP_ENV=prd

---

EXPOSE --> Container listens on defined port numnber.

EXPOSE 80

---

VOLUME --> Create a mopunt point and marks it as shared volume with container.

VOLUME /home/ec2-user/myweb

---

USER --> sets the user to use when we are running this image.

USER ec2-user
USER appuser
USER 1001

---

LABEL --> We can add metadata to the image

LABEL owner="avinash@avinash.com" version="1.0"

---

SHELL 
HEALTHCHECK
ARG
STOPSIGNAL

---

#Using nginx alpine image
FROM nginx:alpine
# Set the working directory
WORKDIR /usr/share/nginx/html
# Remove default nginx static files
RUN rm -rf .
# Copy static files from the local directory to the nginx html directory
# COPY /home/ec2-user/myweb/* /usr/share/nginx/html
COPY . .
# Expose port 80 to the outside world
EXPOSE 80
#Start nginx server
CMD ["nginx", "-g", "daemon off;"]
#Add owner label
LABEL owner="avinash"

---

docker build .

docker build -t mynginx:v1 .

---

1. Generate an app.js file, and prepare a Dockerfile to run this app.js file. Use Node base image, copy the app.js to contianer and run it.
2. Preapre a Dockerfile
3. build the dockerfile
4. Run the docker image

--

1. Generate an app.py file, and prepare a Dockerfile to run this app.py file. Use a lightweight base image, copy the app.py to contianer and run it.
2. Preapre a Dockerfile
3. build the dockerfile
4. Run the docker image

---

docker login

docker tag awar04-calapp:latest avizway/awar04-calapp:v1

docker push avizway/awar04-calapp:v1

docker pull avizway/awar04-calapp

---


docker rm -f $(docker ps -aq)		--> Remove all Containers (Running and Stopped)
docker rm -f $(docker ps -q)		--> Remove all Containers Stopped containers


We can mount a local directory as a volume to the container. 


docker run -d --name mylocal-mount -p 80:80 -v /home/ec2-user/cal-data/:/usr/share/nginx/html:ro,z nginx-local:latest

---

** docker logs <container-id>		--> View logs from a running / stopped container
docker stats						--> Live CPU, Memory and I/O usage.
docker top <container-id>			--> Shows the running processes inside a container
docker events						--> shows realtime events from docker daemon


Limit Resources to a Container:

docker inspect <container-id>		--> All the configuration related information of the container.

docker inspect --format='{{.HostConfig.Memory}}' mycalapp

docker run -d -p 80:80 --memory=256m --cpus=1 --name mycalapp <image-name>

---

docker rename <old-name> <new-name>		--> Rename a container

docker pause <container-name/id>		--> Will pause all the processes at container level
docker unpause <container-name/id>		--> Will un-pause all the processes at container level

docker cp <localpath> <containerpath>

docker cp ./file1.txt <container>:/tmp	--> Copy a host file to a container / vice versa


docker save -o myimage.tar <image-name>		--> THis will create a zipped file of the given image (You can copy this/ SCP this to another machine in your network)

docker load -i myimage.tar					--> THis will load image from the zip file

docker history <image-name>				--> Shows history of Image layers
	

docker build --no-cache -t <name:tag> .		--> Builds the image, without using any cached layers.

---


Elastic Container Registry : Fully-managed Docker container registry : Share and deploy container software, publicly or privately.

---

Steps : 
1. Login to ECR 
(aws ecr get-login-password --region ap-south-1 | docker login --username AWS --password-stdin 123121312.dkr.ecr.ap-south-1.amazonaws.com)

2. Build the image if you have a Dockerfile (** Skip this step if you already have an image to push)
docker build -t awar04-calapp .


3. Add a tag to push it to the ECR service  (Image name should resemble the ECR URI)

docker tag awar04-calapp:latest 123121312.dkr.ecr.ap-south-1.amazonaws.com/awar04-calapp:latest

--> docker tag local-image-name:tag remote-repo-uri/imagename:tag

docker tag awar04-calapp:latest 828477980115.dkr.ecr.ap-south-1.amazonaws.com/awar04-calapp:latest

docker push 828477980115.dkr.ecr.ap-south-1.amazonaws.com/awar04-calapp:latest

---


I want to run 2 docker containers. 

1st DB should start.. once it is up and running, then only DB-GUI Tool container should start.

---


Image : Build : Running --> App --> Down

--

ECS : Elastic COntainer Service : AWS own Containers orchestrator..


EKS

---

Docker = Container (Run a Docker Image to get a container)
ECS = Task (Run a Docker image to get a task (task=container))
EKS = Pod (Run a Docker image to get a pod (pod=container))

---

ECR : Registry service to store the images.

ECS: 

--> Task Definition : Contains all the required settings to run a task. (Image, port, resources, logs)
--> Task : Create a task using the task definition. 
--> service :


EC2 launch Type : We need to provision the cluster of EC2 Instances. 
--> Tasks runs with in that ec2 instances. 
--> We are responsible for Scaling, Patching and monitoring the ec2 instances.

Fargate Launch Type : We dont manage the servers. Its serverless architecture. 
--> AWS handles the Scaling, Patching and monitoring the ec2 instances that runs in backend.


ECS Anywhere : We can run the workload on our own hardware, Use ECS for orchestaration purpose.
--> We have to take care about the HW availability, OS Install, OS patching.. 
--> AWS ECS help us to run, scale the tasks.

--

ECR : Image in Repo

ECS : 
--> create a Cluster : Choosed "fargate"
--> create a task Definition : Selected settings i.e; deployment type (fargate), CPU, Memory, Image, port number and logs configuration..
--> Create a Task : Use a task definition, Choose a VPC, Subnet, SG and Enable Puboic IP. Test the output.

---

Service : We can choose Desired count, if any task failed, it automatically provisions a new task. Always, make sure desired count and actual count are same.
We can choose deployment strategies "Rolling updates" and "blue/green" deployment mothods.


============

Container is stopping suddenly..!!!
1. Verify logs (docker logs <container-name/id>)
2. Verify memory usage (OOM (out of memory) Kills) --> Run "docker inspect <container-name/id>" 
	OOMkilled: true --> Kill the container if no memory
3. docker stats <container-name/id>	

---

After restarting your container (mysql), you dont see any data. How you troubleshoot / fix this issue.?

1. If you are running a container without volume configuration, data stores temp. make sure to create and attach a volume.
2. Mount a local path to container. 

---

Your docker build is taking 15 min to build the dependencies, then image is ready. What changes/strategeies you apply to fix this issue.?
How you speedup the build process.

1. Use chaching to speedup the process
2. Use light weight images
3. Use multistage build mechanism.

--

what are the steps involved in preparing the docker file and pushing it to repo.

After writing the docker file
--> Build it with tags
--> Test it locally (run it)
--> Authenticate to Repo Service (Docker hub / ECR)
--> Add tags
--> Push image

--> Pull the image and use it.

---

You want inspect something inside a container. What is the process. 
How can you run commands to identify the issues at container level. 

We can connect to the container..
docker exec -it <container-id> /bin/bash

---

Container 1 is not able to conenct or communicate with another container. How can you fix the issue.!!

verify network modes.
Verify firewall settings/blocks.

--


ResourceInitializationError: unable to pull secrets or registry auth: The task cannot pull registry auth from Amazon ECR: There is a connection issue between the task and Amazon ECR. Check your task network configuration. operation error ECR: GetAuthorizationToken, exceeded maximum number of attempts, 3, https response error StatusCode: 0, RequestID: , request send failed, Post "https://api.ecr.ap-south-1.amazonaws.com/": dial tcp 13.234.8.23:443: i/o timeout


To fix the above issue..

We have 2 options

1. Create a NAT Gateway and provide internet to private subnets (where ECS tasks running), then task can connect to ecr and pull the images.

2. Create VPC endpoints  (NO INTERNET)
	--> ecr.api : Allow ecs to call ecr api (to get image info)
	--> ecr.dkr : Enable Docker to pull image from ECR
	--> Cloudwatch EP : To store logs, tqask needs cloudwatch endpoint also.
	--> S3 : As ECR stores image layers in s3 temp.

---











