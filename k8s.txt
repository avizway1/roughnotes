---

Kitchen Stove / Cooking equipments --> Container Runtime : Docker Engine / CRI-O / ContainerD

Container Image / Docker Image : Entire app containerise and made as an Image..

Container Orchestration : Kitchen Manager : Amazon ECS, K8s, EKS, Docker Swarm, Apache Mesos..

Container Registry : Cookbook : Docker Hub, ECR, Azure Container Registry..

--

Kubernetes / K8s : 

Control plane (Brain of K8s): 

API-Server / Kube-apiserver : Entry / Front door of Kubernetes.. All API requests from users and tools handles by this api-server.

Controller Manager /kube-controller-manager : Ensure the desired state of the cluster (Maintains replicas, Replaces failed pods, Node health management)

Scheduler (kube-scheduler) : Decides where to run the new pod, Based on resource availability.. 

etcd (key-value store) : It stores all cluster data (Configurations, deployments, state).. 

CCM / Cloud Controller Manager : Integrates K8s with cloud providers (AWS, Azure, GCP).. ELB, Storage, Networks.. 


Worker Nodes (Hands of K8s) : EC2 / Fargate / Our own Server.. 

Kubelet : Runs on every worker node we have.. enables/responsible to establish communication with API server.. Ensures the node runs the assigned container.. 

Container Runtime : Runs containers on the Nodes. 

Kube-Proxy : Manages the networking and ensures pods can communicate each other (pod to pod / node to node)..

Pods : The smallest unit in K8s.. A pod contains one or more containers.. 

====

K8s = Container = pod = ECS Task

Pod contains Container.. 

---

Container : Lightweight, standalone and executable unit of software that contains everything needs to run our applicaiton.
Code, runtime, system libraries, dependencies... 

POD : A pod is smallest and simplest deployable unit in K8s. It can contains one or more containers.

Node : Node is nothing but an ec2 instance or a server, where K8s workload runs.. 



---

Pod :

Replica Set : 

Deployment : 

Service : 



---

Control Plane :
api-server : Frontend for K8s..
etcd : Contains or stores cluster metadata in Key and value.. 
kube-controller-manager : Maintans desired cluster state..
kube-scheduler : Desides where pod needs to run..

Worker Node : 
kubelet : communicates with api-server, ensure pods properly running on the nodes.
container runtime : runs the containers.. docker, cri-o, containerd
kube proxy : Manages the communication (Internal or external)
pod : Smallest deployable unit in K8s.. It contains one or more containers.. 

Sidecar container : helper contianers for main containers.. 


---

Pod : Contains our application container..

ReplicaSet : Ensures specified number of identitical pod replicas are running always. 

--> Pod Available
--> Self healing
--> Manual Scaling

** Does not support rolling updates. We need to use Deployment..

Deployment : Deployment maintains the ReplicaSets and it allow "Rolling Updates".

--

Service : Service is an abstractio that defines a logical set of podss. 
Sometimes Pods lifetime is very short.. Depending on pods IP to communicate may lead to communication failure.. So, We can logically group all the pods, that serves same purpose/content, then we can use the service name..


--> ClusterIP : 
--> NodePort : 
--> LoadBalancer : 


---

1. Managed Control plane : AWS manages the Control plane components (API Server, etcd, Scheduler, CM..), AWS takes care about HA/FT.

--> Easily integrate with other AWS services.. VPC, IAM, Cloudwatch, LoadBalancer, s3... 

--> AWS takes care about complete "Control Plane"

--> AWS EKS Data Plane has 4 Options.

--> EC2 - Self managed node group : "WE" will have full control.. (Scaling, os patching..)
	--> We need to use Custom AMIs while launching these instances.
	
--> EC2 - Managed Node group : "AWS" provisions and manages the nodes/instances.
	--> AWS takes care about the updatees, sclaing, patching..
	--> AWS uses "bottlerocket" as default ami
	--> All we need to do is "choose right sized instance".
	
--> Fargate (Serverless)
	--> No nodes to manage, No node group concept.
	--> Directly we can run pods.

--> AWS EKS Auto Mode
	--> AWS takes care about the updatees, sclaing, patching..
	--> We get high configuration instances at very low cost.

---


You should have 2 components.. 

1. AWS CLI Installed and configured
2. eksctl
3. kubectl
	

eksctl create cluster --name=ekswithavinash --version 1.33 --region ap-south-1 --nodegroup-name ng-default --node-type t3.small --nodes 2 --managed --node-ami-family=AmazonLinux2023

---

OIDC : IAM OpenID Connect, This allows AWS IAM to authenticate with K8s service accounts and IAM Permissions and roles.

aws eks describe-cluster --name ekswithavinash --query "cluster.identity.oidc.issuer"

If above command retuned empty, We need to create an OIDC provider.


'''
eksctl utils associate-iam-oidc-provider --region ap-south-1 --cluster ekswithavinash --approve
'''


eksctl get cluster			--> List the eks clusters


kubectl 
 			


eksctl delete cluster --name ekswithavinash

---

kubectl get all 		--> All K8s components present in default namespace

kubectl get all -A		--> List everything, including K8s default namespaces (K8s system pods)

kubectl get pods
kubectl get replicasets		kubectl get rs
kubectl get services		kubectl get svc
kubectl get namespaces		kubectl get ns


kubectl apply -f pod.yaml --dry-run=client
kubectl apply -f pod.yaml
kubectl get pods


kubectl describe pods awar04-pod

kubectl delete pod rs-call-app-s4kqt
kubectl delete pod/rs-call-app-s4kqt


--------

K8s Deployment Strategies :


Rolling Update : This method gradually replaces old pods with new pods. As we have addl pods also to deliver our applicatiom, we dont see any downtimes.
Most of the day-to-day deployments prefer this.

MaxSurge : Extra Pods allowed during the update
MaxUnavailable : How many can be down

---

Recreate : All existing pods will be terminated, then new pods starts running. We will get a very short downtime. Service delivering pods count goes to 0, then it will start sending traffic to new pods.

---

Blue/Green Deployment : Blue (Current Environment) and green (new Env). 

---

Canary Release : Send a small percentage of real traffic to the newer version.. (1-5%).. If everything is good, Then increase the % to 25%, 50%, 100%.
--> Old and New environments works side-by-side. 

---

A/B Deployment : Route some of the users to one version of application.. another set of users to another set of application.. New UI experiments.. 

---

Shadow Deployment : We can duplicate the traffic without any user impact. 

---





